# -*- coding: utf-8 -*-
"""CSE3000FinalProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11EnDLB0X4KMpLe5lTG1jdZqN1PC1pbWN
"""

import os
import pandas as pd
import tensorflow as tf
import numpy as np

file_path = os.path.join('/content/train.csv')

df = pd.read_csv(file_path)

df = pd.read_csv(file_path)

df.columns

# Show examples of toxic text
df[df['toxic']==1].head()

df.tail()

df.iloc[3]['comment_text']

df[df.columns[2:]].iloc[3]

from tensorflow.keras.layers import TextVectorization

X = df['comment_text']
y = df[df.columns[2:]].values

y.shape

df.columns

df[df.columns[2:]]

X

MAX_FEATURES = 200000

vectorizer = TextVectorization(max_tokens = MAX_FEATURES, output_sequence_length =1800, output_mode = 'int')

vectorizer.adapt(X.values)
vectorizer.get_vocabulary()

vectorized_text = vectorizer(X.values)

dataset = tf.data.Dataset.from_tensor_slices((vectorized_text,y))
dataset = dataset.cache()
dataset = dataset.shuffle(160000)
dataset = dataset.batch(16)
dataset = dataset.prefetch(8)

batch_X,batch_y = dataset.as_numpy_iterator().next()
batch_y.shape

train = dataset.take(int(len(dataset)*.7))
val= dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))
test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))

train_generator = train.as_numpy_iterator()

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding,LSTM,Dropout,Bidirectional,Dense

model = Sequential()
model.add(Embedding(MAX_FEATURES+1,32))
model.add(Bidirectional(LSTM(32,activation = 'tanh')))
model.add(Dense(128,activation = 'relu'))
model.add(Dense(256, activation = 'relu'))
model.add(Dense(128, activation = 'relu'))
model.add(Dense(6 , activation = 'sigmoid'))

model.compile(loss = 'BinaryCrossentropy', optimizer = 'Adam', metrics=['accuracy'])

model.summary()

history = model.fit(train, epochs=1, validation_data=val)

from matplotlib import pyplot as plt

plt.figure(figsize=(8, 5))
pd.DataFrame(history.history).plot()
plt.show()

impot_text = vectorizer ('You suck!')

batch = test.as_numpy_iterator().next()

batch_X,batch_y = test.as_numpy_iterator().next()

(model.predict(batch_X)>0.5).astype(int)

from tensorflow.keras.metrics import Precision , Recall , CategoricalAccuracy

pre = Precision()
re = Recall()
acc = CategoricalAccuracy()

for batch in test.as_numpy_iterator():
    X_true,y_true = batch
    yhat = model.predict(X_true)
    y_true = y_true.flatten()
    yhat = yhat.flatten()
    pre.update_state(y_true,yhat)
    re.update_state(y_true,yhat)
    acc.update_state(y_true, yhat)

print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')

import gradio as gr
import tensorflow as tf

model.save ('toxiccity.h5')

model = tf.keras.models.load_model('toxiccity.h5')

input_str = vectorizer('hey i freaken hate you ! I am coming for you. I\'m going to hurt you')

res = model.predict(np.expand_dims(input_str,0))

df.columns[2:]

def score_comment(comment):
    vectorized_comment = vectorizer ([comment])
    results = model.predict(vectorized_comment)


    text = ''
    for idx, col in enumerate (df.columns[2:-1]):
        text+= '{} :{}\n'.format(col,results[0][idx]>0.5)
    return text

interface = gr.Interface(fn=score_comment,
                         inputs=gr.Textbox(lines=2, placeholder='Comment to score'),
                         outputs='text')

interface.launch(share = True)